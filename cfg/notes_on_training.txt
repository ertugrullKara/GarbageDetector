Training for classification===
 We train the network on
the standard ImageNet 1000 class classification dataset for
160 epochs using stochastic gradient descent with a starting
learning rate of 0.1, polynomial rate decay with a power of
4, weight decay of 0.0005 and momentum of 0.9 using the
Darknet neural network framework [13]. During training
we use standard data augmentation tricks including random
crops, rotations, and hue, saturation, and exposure shifts.
As discussed above, after our initial training on images
at 224 × 224 we fine tune our network at a larger size, 448.
For this fine tuning we train with the above parameters but
for only 10 epochs and starting at a learning rate of 10 −3 . At
this higher resolution our network achieves a top-1 accuracy
of 76.5% and a top-5 accuracy of 93.3%.

Training for detection==
 We modify this network for de-
tection by removing the last convolutional layer and instead
adding on three 3 × 3 convolutional layers with 1024 fil-
ters each followed by a final 1 × 1 convolutional layer with
the number of outputs we need for detection. For VOC we
predict 5 boxes with 5 coordinates each and 20 classes per
box so 125 filters. We also add a passthrough layer from the
final 3 × 3 × 512 layer to the second to last convolutional
layer so that our model can use fine grain features.
We train the network for 160 epochs with a starting
learning rate of 10 −3 , dividing it by 10 at 60 and 90 epochs
We use a weight decay of 0.0005 and momentum of 0.9.
We use a similar data augmentation to YOLO and SSD with
random crops, color shifting, etc. We use the same training
strategy on COCO and VOC.


anchor boxes===
 Instead of choosing priors by hand, we run k-means
clustering on the training set bounding boxes to automatically find good priors. If we use standard k-means with
Euclidean distance larger boxes generate more error than
smaller boxes. However, what we really want are priors
that lead to good IOU scores, which is independent of the
size of the box. Thus for our distance metric we use:
d(box, centroid) = 1 − IOU(box, centroid)
We run k-means for various values of k and plot the av-
erage IOU with closest centroid, see Figure 2. We choose
k = 5 as a good tradeoff between model complexity and
high recall. The cluster centroids are significantly different
than hand-picked anchor boxes. There are fewer short, wide
boxes and more tall, thin boxes.


***********************
Last convolution layers filter number to match a formula described in paper. Which is (coords + classes + 1) * num

